{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to gym2vid","text":""},{"location":"#features","title":"Features","text":"<ul> <li>Train RL agents on Gymnasium environments</li> <li>Record gameplay videos</li> <li>Annotate videos with state and action information</li> <li>Slow down videos for better visualization</li> <li>Support for custom environments</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from gym2vid import Runner\n\n# Initialize the runner with an environment\nrunner = Runner(\"FrozenLake-v1\")\n\n# Train and record episodes\nrunner.train_and_record(num_episodes=10, output_dir=\"./videos\")\n\n# Create annotated video\nrunner.create_annotated_video(slow_factor=2.0)\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#runner-class","title":"Runner Class","text":"<p>The main interface for training and recording:</p> <ul> <li><code>train_and_record(num_episodes, output_dir)</code>: Train the agent and record episodes</li> <li><code>create_annotated_video(slow_factor)</code>: Create an annotated video with state/action information</li> </ul>"},{"location":"#configuration","title":"Configuration","text":"<p>You can customize the training parameters:</p> <pre><code>config = {\n    \"learning_rate\": 0.001,\n    \"gamma\": 0.99,\n    \"epsilon\": 0.1\n}\nrunner = Runner(\"FrozenLake-v1\", config=config)\n</code></pre>"},{"location":"#license","title":"License","text":"<p>MIT License</p>"},{"location":"api/","title":"API Reference","text":"<p>Main interface for training and recording gym environments.</p> Source code in <code>gym2vid/gym2vid/runner.py</code> <pre><code>class Runner:\n    \"\"\"Main interface for training and recording gym environments.\"\"\"\n\n    def __init__(self, env_name: str, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the Runner.\n\n        Args:\n            env_name: Name of the Gymnasium environment\n            config: Optional configuration dictionary for training parameters\n        \"\"\"\n        if not ML_DEPENDENCIES_AVAILABLE:\n            print(\n                \"Warning: ML dependencies (torch, stable-baselines3, sb3-contrib) not available.\"\n            )\n            print(\n                \"Some functionality will be limited. Install with: pip install torch stable-baselines3 sb3-contrib\"\n            )\n\n        self.env_name = env_name\n        self.config = config or {}\n        self.model_path = None\n        self.output_dir = None\n\n    def train_and_record(\n        self,\n        num_episodes: int,\n        output_dir: str,\n        train_timesteps: int = 10000,\n        n_train_envs: int = 2,\n    ) -&gt; None:\n        \"\"\"Train the agent and record episodes.\n\n        Args:\n            num_episodes: Number of episodes to record\n            output_dir: Directory to save videos and data\n            train_timesteps: Number of timesteps to train for\n            n_train_envs: Number of parallel environments for training\n        \"\"\"\n        if not ML_DEPENDENCIES_AVAILABLE:\n            raise RuntimeError(\n                \"ML dependencies not available. Install with: pip install torch stable-baselines3 sb3-contrib\"\n            )\n\n        self.output_dir = output_dir\n        os.makedirs(output_dir, exist_ok=True)\n\n        # Train the model\n        model_dir = os.path.join(output_dir, \"model\")\n        os.makedirs(model_dir, exist_ok=True)\n        save_model_name = os.path.join(\n            model_dir, f\"trpo_{self.env_name.replace('/', '_')}\"\n        )\n        save_model_name_zip = save_model_name + \".zip\"\n\n        if not os.path.exists(save_model_name_zip):\n            env = make_vec_env(\n                self.env_name, n_envs=n_train_envs, vec_env_cls=SubprocVecEnv\n            )\n            env.metadata[\"render_fps\"] = [24 for _ in range(n_train_envs)]\n\n            # Apply any custom config and force CPU for TRPO\n            model_kwargs = {\n                \"verbose\": 1,\n                \"device\": \"cpu\",  # Force CPU for TRPO as it's not optimized for GPU\n            }\n\n            model = TRPO(\"MlpPolicy\", env, **model_kwargs)\n            model.learn(total_timesteps=train_timesteps)\n            model.save(save_model_name)\n            env.close()\n\n        self.model_path = save_model_name_zip\n\n        # Record episodes\n        video_dir = os.path.join(output_dir, \"videos\", self.env_name)\n        os.makedirs(video_dir, exist_ok=True)\n\n        with Pool(processes=min(num_episodes, torch.cuda.device_count() or 1)) as pool:\n            results = []\n            with tqdm(total=num_episodes) as pbar:\n\n                def update_pbar(*args):\n                    pbar.update()\n\n                for episode_id in range(num_episodes):\n                    results.append(\n                        pool.apply_async(\n                            simulate,\n                            (\n                                self.env_name,\n                                self.model_path,\n                                episode_id,\n                                episode_id % (torch.cuda.device_count() or 1),\n                                output_dir,\n                            ),\n                            callback=update_pbar,\n                            error_callback=lambda x: print(f\"Error: {x}\"),\n                        )\n                    )\n\n                # Wait for all episodes to complete and check for failures\n                failed_episodes = []\n                for episode_id, result in enumerate(results):\n                    try:\n                        if not result.get():\n                            failed_episodes.append(episode_id)\n                    except Exception as e:\n                        print(f\"Episode {episode_id} failed with error: {e}\")\n                        failed_episodes.append(episode_id)\n\n                if failed_episodes:\n                    print(\n                        f\"Warning: Episodes {failed_episodes} failed to record properly\"\n                    )\n\n    def create_annotated_video(self, slow_factor: float = 1.0) -&gt; None:\n        \"\"\"Create an annotated video with state/action information.\n\n        Creates annotated videos for all episodes by overlaying state and action\n        information on the recorded videos. Optionally creates slowed-down\n        versions of these annotated videos.\n\n        Args:\n            slow_factor: Factor to slow down the video by. Default is 1.0 (no slowing).\n                Values &gt; 1.0 will slow the video (e.g., 2.0 means half speed).\n\n        Raises:\n            ValueError: If no output directory is set (train_and_record must be called first).\n            RuntimeError: If source video files are missing or annotation fails.\n        \"\"\"\n        if not self.output_dir:\n            raise ValueError(\"No output directory set. Run train_and_record first.\")\n\n        video_dir = os.path.join(self.output_dir, \"videos\", self.env_name)\n        if not os.path.exists(video_dir):\n            raise RuntimeError(f\"Video directory not found: {video_dir}\")\n\n        # Get list of episode files\n        video_files = [\n            f\n            for f in os.listdir(video_dir)\n            if f.endswith(\".mp4\") and \"annotated\" not in f\n        ]\n        if not video_files:\n            raise RuntimeError(f\"No video files found in {video_dir}\")\n\n        successful_annotations = 0\n        for video_file in video_files:\n            try:\n                episode_id = int(video_file.split(\"_episodes_\")[1].split(\".\")[0])\n                mp4_path = os.path.join(video_dir, video_file)\n                pkl_path = os.path.join(\n                    video_dir,\n                    f\"{self.env_name.replace('/', '_')}_episodes_{episode_id}.pkl\",\n                )\n                output_path = os.path.join(\n                    video_dir,\n                    f\"{self.env_name.replace('/', '_')}_episodes_{episode_id}_annotated.mp4\",\n                )\n\n                if not os.path.exists(mp4_path):\n                    print(f\"Warning: Source video not found: {mp4_path}\")\n                    continue\n                if not os.path.exists(pkl_path):\n                    print(f\"Warning: Pickle file not found: {pkl_path}\")\n                    continue\n\n                create_annotated_video(mp4_path, pkl_path, output_path)\n                successful_annotations += 1\n\n                if slow_factor != 1.0:\n                    slower_output_path = os.path.join(\n                        video_dir,\n                        f\"{self.env_name.replace('/', '_')}_episodes_{episode_id}_annotated_slowed_{slow_factor}x.mp4\",\n                    )\n                    create_slowed_video(output_path, slower_output_path, slow_factor)\n\n            except Exception as e:\n                print(f\"Failed to annotate episode {episode_id}: {e}\")\n                continue\n\n        if successful_annotations == 0:\n            raise RuntimeError(\"Failed to create any annotated videos\")\n</code></pre>"},{"location":"api/#gym2vid.gym2vid.runner.Runner.__init__","title":"<code>__init__(env_name, config=None)</code>","text":"<p>Initialize the Runner.</p> <p>Parameters:</p> Name Type Description Default <code>env_name</code> <code>str</code> <p>Name of the Gymnasium environment</p> required <code>config</code> <code>Optional[Dict[str, Any]]</code> <p>Optional configuration dictionary for training parameters</p> <code>None</code> Source code in <code>gym2vid/gym2vid/runner.py</code> <pre><code>def __init__(self, env_name: str, config: Optional[Dict[str, Any]] = None):\n    \"\"\"Initialize the Runner.\n\n    Args:\n        env_name: Name of the Gymnasium environment\n        config: Optional configuration dictionary for training parameters\n    \"\"\"\n    if not ML_DEPENDENCIES_AVAILABLE:\n        print(\n            \"Warning: ML dependencies (torch, stable-baselines3, sb3-contrib) not available.\"\n        )\n        print(\n            \"Some functionality will be limited. Install with: pip install torch stable-baselines3 sb3-contrib\"\n        )\n\n    self.env_name = env_name\n    self.config = config or {}\n    self.model_path = None\n    self.output_dir = None\n</code></pre>"},{"location":"api/#gym2vid.gym2vid.runner.Runner.create_annotated_video","title":"<code>create_annotated_video(slow_factor=1.0)</code>","text":"<p>Create an annotated video with state/action information.</p> <p>Creates annotated videos for all episodes by overlaying state and action information on the recorded videos. Optionally creates slowed-down versions of these annotated videos.</p> <p>Parameters:</p> Name Type Description Default <code>slow_factor</code> <code>float</code> <p>Factor to slow down the video by. Default is 1.0 (no slowing). Values &gt; 1.0 will slow the video (e.g., 2.0 means half speed).</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no output directory is set (train_and_record must be called first).</p> <code>RuntimeError</code> <p>If source video files are missing or annotation fails.</p> Source code in <code>gym2vid/gym2vid/runner.py</code> <pre><code>def create_annotated_video(self, slow_factor: float = 1.0) -&gt; None:\n    \"\"\"Create an annotated video with state/action information.\n\n    Creates annotated videos for all episodes by overlaying state and action\n    information on the recorded videos. Optionally creates slowed-down\n    versions of these annotated videos.\n\n    Args:\n        slow_factor: Factor to slow down the video by. Default is 1.0 (no slowing).\n            Values &gt; 1.0 will slow the video (e.g., 2.0 means half speed).\n\n    Raises:\n        ValueError: If no output directory is set (train_and_record must be called first).\n        RuntimeError: If source video files are missing or annotation fails.\n    \"\"\"\n    if not self.output_dir:\n        raise ValueError(\"No output directory set. Run train_and_record first.\")\n\n    video_dir = os.path.join(self.output_dir, \"videos\", self.env_name)\n    if not os.path.exists(video_dir):\n        raise RuntimeError(f\"Video directory not found: {video_dir}\")\n\n    # Get list of episode files\n    video_files = [\n        f\n        for f in os.listdir(video_dir)\n        if f.endswith(\".mp4\") and \"annotated\" not in f\n    ]\n    if not video_files:\n        raise RuntimeError(f\"No video files found in {video_dir}\")\n\n    successful_annotations = 0\n    for video_file in video_files:\n        try:\n            episode_id = int(video_file.split(\"_episodes_\")[1].split(\".\")[0])\n            mp4_path = os.path.join(video_dir, video_file)\n            pkl_path = os.path.join(\n                video_dir,\n                f\"{self.env_name.replace('/', '_')}_episodes_{episode_id}.pkl\",\n            )\n            output_path = os.path.join(\n                video_dir,\n                f\"{self.env_name.replace('/', '_')}_episodes_{episode_id}_annotated.mp4\",\n            )\n\n            if not os.path.exists(mp4_path):\n                print(f\"Warning: Source video not found: {mp4_path}\")\n                continue\n            if not os.path.exists(pkl_path):\n                print(f\"Warning: Pickle file not found: {pkl_path}\")\n                continue\n\n            create_annotated_video(mp4_path, pkl_path, output_path)\n            successful_annotations += 1\n\n            if slow_factor != 1.0:\n                slower_output_path = os.path.join(\n                    video_dir,\n                    f\"{self.env_name.replace('/', '_')}_episodes_{episode_id}_annotated_slowed_{slow_factor}x.mp4\",\n                )\n                create_slowed_video(output_path, slower_output_path, slow_factor)\n\n        except Exception as e:\n            print(f\"Failed to annotate episode {episode_id}: {e}\")\n            continue\n\n    if successful_annotations == 0:\n        raise RuntimeError(\"Failed to create any annotated videos\")\n</code></pre>"},{"location":"api/#gym2vid.gym2vid.runner.Runner.train_and_record","title":"<code>train_and_record(num_episodes, output_dir, train_timesteps=10000, n_train_envs=2)</code>","text":"<p>Train the agent and record episodes.</p> <p>Parameters:</p> Name Type Description Default <code>num_episodes</code> <code>int</code> <p>Number of episodes to record</p> required <code>output_dir</code> <code>str</code> <p>Directory to save videos and data</p> required <code>train_timesteps</code> <code>int</code> <p>Number of timesteps to train for</p> <code>10000</code> <code>n_train_envs</code> <code>int</code> <p>Number of parallel environments for training</p> <code>2</code> Source code in <code>gym2vid/gym2vid/runner.py</code> <pre><code>def train_and_record(\n    self,\n    num_episodes: int,\n    output_dir: str,\n    train_timesteps: int = 10000,\n    n_train_envs: int = 2,\n) -&gt; None:\n    \"\"\"Train the agent and record episodes.\n\n    Args:\n        num_episodes: Number of episodes to record\n        output_dir: Directory to save videos and data\n        train_timesteps: Number of timesteps to train for\n        n_train_envs: Number of parallel environments for training\n    \"\"\"\n    if not ML_DEPENDENCIES_AVAILABLE:\n        raise RuntimeError(\n            \"ML dependencies not available. Install with: pip install torch stable-baselines3 sb3-contrib\"\n        )\n\n    self.output_dir = output_dir\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Train the model\n    model_dir = os.path.join(output_dir, \"model\")\n    os.makedirs(model_dir, exist_ok=True)\n    save_model_name = os.path.join(\n        model_dir, f\"trpo_{self.env_name.replace('/', '_')}\"\n    )\n    save_model_name_zip = save_model_name + \".zip\"\n\n    if not os.path.exists(save_model_name_zip):\n        env = make_vec_env(\n            self.env_name, n_envs=n_train_envs, vec_env_cls=SubprocVecEnv\n        )\n        env.metadata[\"render_fps\"] = [24 for _ in range(n_train_envs)]\n\n        # Apply any custom config and force CPU for TRPO\n        model_kwargs = {\n            \"verbose\": 1,\n            \"device\": \"cpu\",  # Force CPU for TRPO as it's not optimized for GPU\n        }\n\n        model = TRPO(\"MlpPolicy\", env, **model_kwargs)\n        model.learn(total_timesteps=train_timesteps)\n        model.save(save_model_name)\n        env.close()\n\n    self.model_path = save_model_name_zip\n\n    # Record episodes\n    video_dir = os.path.join(output_dir, \"videos\", self.env_name)\n    os.makedirs(video_dir, exist_ok=True)\n\n    with Pool(processes=min(num_episodes, torch.cuda.device_count() or 1)) as pool:\n        results = []\n        with tqdm(total=num_episodes) as pbar:\n\n            def update_pbar(*args):\n                pbar.update()\n\n            for episode_id in range(num_episodes):\n                results.append(\n                    pool.apply_async(\n                        simulate,\n                        (\n                            self.env_name,\n                            self.model_path,\n                            episode_id,\n                            episode_id % (torch.cuda.device_count() or 1),\n                            output_dir,\n                        ),\n                        callback=update_pbar,\n                        error_callback=lambda x: print(f\"Error: {x}\"),\n                    )\n                )\n\n            # Wait for all episodes to complete and check for failures\n            failed_episodes = []\n            for episode_id, result in enumerate(results):\n                try:\n                    if not result.get():\n                        failed_episodes.append(episode_id)\n                except Exception as e:\n                    print(f\"Episode {episode_id} failed with error: {e}\")\n                    failed_episodes.append(episode_id)\n\n            if failed_episodes:\n                print(\n                    f\"Warning: Episodes {failed_episodes} failed to record properly\"\n                )\n</code></pre>"}]}